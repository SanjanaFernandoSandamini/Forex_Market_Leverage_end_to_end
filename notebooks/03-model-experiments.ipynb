# 03-model-experiments.ipynb

# Train and compare baseline XGBoost with risk features included

import pandas as pd
from src.models.train import prepare_data, train_xgb

processed_file = 'data/processed/EURUSD_60min.csv'
X, y = prepare_data(processed_file)

print(f"Training features shape: {X.shape}")
print(f"Training target distribution:\n{y.value_counts(normalize=True)}")

model, score = train_xgb(X, y)
print(f"Baseline XGBoost Accuracy (with risk features): {score:.4f}")

# You can add LSTM training here (future extension)

# Optional: feature importance plot
import matplotlib.pyplot as plt
import xgboost as xgb

booster = model.get_booster()
xgb.plot_importance(booster, importance_type='gain', max_num_features=10)
plt.title('XGBoost Feature Importance')
plt.show()
